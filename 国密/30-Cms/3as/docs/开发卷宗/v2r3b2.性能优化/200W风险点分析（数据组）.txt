一，数据库性能瓶颈
1，联表查询慢
eg. tas中的联表逻辑

2，表读写互锁
eg. myisam表锁并发高时阻塞，tas权限划归

3，数据库访问量大
eg. 数据库的IOPS是比较低的

预案：
存储引擎由myisam改为innodb。
数据库服务器独立部署，调大innodb引擎的缓存大小，尽量让尽量多的数据保存在内存中。
mycat读写分离，需要分析哪些业务是写后立即读取一次的（读写分离方案时需要特殊处理此类业务）。

访问量向redis引导（比如之前未放置的用户权限数据），减轻数据库的压力。
大量联表的业务分解，需要在方便性和处理性能之间找平衡，或者拼装数据外包，由多个模块处理。
联表场景反范式设计，用户设备权限与用户设备能力权限合并。

二，redis性能瓶颈
1，redis访问量大

2，redis持久化的影响
XXH测试存在影响的

预案：
redis集群方案，官方的redis-cluster（有看到说不稳定）和第三方大公司的redis-proxy。
存储于redis中的数据操作API，结合业务实现，在redis中编写处理脚本，避免冗余数据传输。

三，模块通信量大
1，模块收发消息大
eg. 单模块收发消息瓶颈，1000个cu同时按需获取设备列表tas消息传输压力

预案：
sip通信性能优化
找出最大的通信量的信令，借用redis通道或采用osp协议通信
模块集群化，多个模块同时服务

四，数据量的影响
1，由于数据量大处理时间长，处理过程中数据变更导致旧数据覆盖新数据
此问题的概率将比原来大的多
eg. gbs中视频源的经纬度同步业务

预案：
此问题其实数据量小时也存在，需要调整相应逻辑的时序。

2，由于数据量原来有些场景单次查询所有数据的场景，可能引发内存不足
eg. gbu遇到过，查询gbtable 90多万条记录时debug版本地址空间达到3G，导致分配内存失败。

3，很多数据同步对redis的递归调用
通常会阻塞主线程
eg. cmu, tas, gbu, gbs中都存在类似的场景

4，批量操作相关波及优化
eg. gbs与cmu之间的批量注册但是uas中日志记录没有批量化

5，gbs组织设备树上报上级时瓶颈

6，打印全量数据的调试命令
全部打印变得没法看，还会阻塞

7，由于无权限数据而多返回很多数据给客户端的场景
eg. mps图元查询时未过滤用户没有的图元，als告警联动配置等
预案：今天定的方案是dps进行叠加过滤

8，由于查询过滤条件不充分而多返回很多数据给客户端的场景
eg. mps图元查询时未过滤用户
预案：mps根据查询条件过滤一下
